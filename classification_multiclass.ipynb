{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitvenvvenvb8d9021ca51d43cfbc34908d99b12918",
   "display_name": "Python 3.8.3 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mnist_train = pd.read_csv(\"datasets/digit_recognizer/mnist_train.csv\").to_numpy()\n",
    "mnist_test = pd.read_csv(\"datasets/digit_recognizer/mnist_test.csv\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from softmax_regression import SoftmaxRegression\n",
    "from knn import KNN\n",
    "\n",
    "X_train = mnist_train[:, 1:]\n",
    "X_train = X_train / 255\n",
    "y_train = mnist_train[:, 0]\n",
    "X_test = mnist_test[:, 1:]\n",
    "X_test = X_test / 255\n",
    "y_test = mnist_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch: 1\tLoss: 0.6637152190270612\nEpoch: 2\tLoss: 0.529887927955265\nEpoch: 3\tLoss: 0.4653619760902281\nEpoch: 4\tLoss: 0.43578830991681955\nEpoch: 5\tLoss: 0.4057132642008165\nEpoch: 6\tLoss: 0.3873948891775045\nEpoch: 7\tLoss: 0.3677245431054046\nEpoch: 8\tLoss: 0.35609836954679175\nEpoch: 9\tLoss: 0.34580636262366354\nEpoch: 10\tLoss: 0.3366016286229178\nEpoch: 11\tLoss: 0.32822219958100596\nEpoch: 12\tLoss: 0.32662209327377145\nEpoch: 13\tLoss: 0.3148022507937026\nEpoch: 14\tLoss: 0.3110302495405224\nEpoch: 15\tLoss: 0.31520403608599634\nEpoch: 16\tLoss: 0.30059375672877375\nEpoch: 17\tLoss: 0.3017510474427592\nEpoch: 18\tLoss: 0.30009747003932324\nEpoch: 19\tLoss: 0.2962396381183533\nEpoch: 20\tLoss: 0.2939290933539009\nEpoch: 21\tLoss: 0.2847086339508297\nEpoch: 22\tLoss: 0.28946654408070693\nEpoch: 23\tLoss: 0.2841011368941066\nEpoch: 24\tLoss: 0.2784573085947632\nEpoch: 25\tLoss: 0.28088984843006415\nEpoch: 26\tLoss: 0.2792882853881554\nEpoch: 27\tLoss: 0.2761543936875321\nEpoch: 28\tLoss: 0.2725873718916011\nEpoch: 29\tLoss: 0.26962406055329013\nEpoch: 30\tLoss: 0.2688000032552193\nEpoch: 31\tLoss: 0.2706999998125257\nEpoch: 32\tLoss: 0.2723787620493314\nEpoch: 33\tLoss: 0.27050515404239706\nEpoch: 34\tLoss: 0.2652535939045864\nEpoch: 35\tLoss: 0.2649052980361112\nEpoch: 36\tLoss: 0.27404001460837646\nEpoch: 37\tLoss: 0.26170642373755354\nEpoch: 38\tLoss: 0.26243573695189293\nEpoch: 39\tLoss: 0.26577453441027393\nEpoch: 40\tLoss: 0.2607168715040636\nEpoch: 41\tLoss: 0.2631183179016946\nEpoch: 42\tLoss: 0.26136003115011164\nEpoch: 43\tLoss: 0.25763726568578516\nEpoch: 44\tLoss: 0.26078911083258527\nEpoch: 45\tLoss: 0.260979132405667\nEpoch: 46\tLoss: 0.25976154523293754\nEpoch: 47\tLoss: 0.25490572457973637\nEpoch: 48\tLoss: 0.2578550914035781\nEpoch: 49\tLoss: 0.2535406261676261\nEpoch: 50\tLoss: 0.2552037897907956\nEpoch: 51\tLoss: 0.2583587653199858\nEpoch: 52\tLoss: 0.2504861607619777\nEpoch: 53\tLoss: 0.25573314404344655\nEpoch: 54\tLoss: 0.25092104167200985\nEpoch: 55\tLoss: 0.2535690265143765\nEpoch: 56\tLoss: 0.2542836991652245\nEpoch: 57\tLoss: 0.2516058922836398\nEpoch: 58\tLoss: 0.25316355706711435\nEpoch: 59\tLoss: 0.24920796979045304\nEpoch: 60\tLoss: 0.2526362646315989\nEpoch: 61\tLoss: 0.25020418442505565\nEpoch: 62\tLoss: 0.24692583211935337\nEpoch: 63\tLoss: 0.25166542667334235\nEpoch: 64\tLoss: 0.24781656337500513\nEpoch: 65\tLoss: 0.2540591215907691\nEpoch: 66\tLoss: 0.24735031683204875\nEpoch: 67\tLoss: 0.252031179191985\nEpoch: 68\tLoss: 0.24617925192824508\nEpoch: 69\tLoss: 0.24908201383412823\nEpoch: 70\tLoss: 0.24750184671627365\nEpoch: 71\tLoss: 0.24412561568247276\nEpoch: 72\tLoss: 0.24475532342237682\nEpoch: 73\tLoss: 0.2467681853395328\nEpoch: 74\tLoss: 0.24621476131471062\nEpoch: 75\tLoss: 0.2503518996694822\nEpoch: 76\tLoss: 0.2432577153232597\nEpoch: 77\tLoss: 0.2454303722804638\nEpoch: 78\tLoss: 0.2462225806927509\nEpoch: 79\tLoss: 0.24647561438455096\nEpoch: 80\tLoss: 0.24220331877700355\nEpoch: 81\tLoss: 0.24279244513186243\nEpoch: 82\tLoss: 0.24332217429316855\nEpoch: 83\tLoss: 0.2434470614525261\nEpoch: 84\tLoss: 0.2500288453589884\nEpoch: 85\tLoss: 0.24408730859425584\nEpoch: 86\tLoss: 0.24478309655447406\nEpoch: 87\tLoss: 0.24001835713256406\nEpoch: 88\tLoss: 0.24137703775462405\nEpoch: 89\tLoss: 0.24360435680445952\nEpoch: 90\tLoss: 0.24362438790788032\nEpoch: 91\tLoss: 0.24613372254890126\nEpoch: 92\tLoss: 0.23960919610875975\nEpoch: 93\tLoss: 0.24127736320517768\nEpoch: 94\tLoss: 0.23997644458999162\nEpoch: 95\tLoss: 0.24004713234279637\nEpoch: 96\tLoss: 0.24467719913543776\nEpoch: 97\tLoss: 0.24503391975075822\nEpoch: 98\tLoss: 0.24610943736748206\nEpoch: 99\tLoss: 0.2485742551977545\nEpoch: 100\tLoss: 0.241112431994534\nAccuracy: 0.922\n"
    }
   ],
   "source": [
    "softmax_regression_model = SoftmaxRegression(X_train, y_train)\n",
    "W, loss_hist = softmax_regression_model.fit(lr=0.05, nepoches=100, hist=True)\n",
    "softmax_precision = softmax_regression_model.test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.9642\n"
    }
   ],
   "source": [
    "knn_model = KNN(X_train[:40000], y_train[:40000], k=10, weights='distance')\n",
    "knn_precision = knn_model.test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}