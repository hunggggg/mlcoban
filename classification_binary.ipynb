{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitvenvvenvb8d9021ca51d43cfbc34908d99b12918",
   "display_name": "Python 3.8.3 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "breast_cancer = pd.read_csv(\"datasets/breast_cancer_diagnostic/data.csv\")\n",
    "breast_cancer.loc[breast_cancer['diagnosis'] == 'M', 'diagnosis'] = 1\n",
    "breast_cancer.loc[breast_cancer['diagnosis'] == 'B', 'diagnosis'] = 0\n",
    "X = breast_cancer.iloc[:, 2:-1].to_numpy()\n",
    "y = breast_cancer['diagnosis'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_min, X_max = np.min(X, axis=0), np.max(X, axis=0)\n",
    "X = (X - X_min) / (X_max - X_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logistic_regression import LogisticRegression\n",
    "from svm import SVM\n",
    "\n",
    "mix_ids = np.random.permutation(X.shape[0])\n",
    "train_N = int(X.shape[0] * .8)\n",
    "train_set, test_set = mix_ids[:train_N], mix_ids[train_N:]\n",
    "X_train, y_train = X[train_set], y[train_set]\n",
    "X_test, y_test = X[test_set], y[test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch: 1\tLoss: 0.48209405971813357\nEpoch: 2\tLoss: 0.37464966784111\nEpoch: 3\tLoss: 0.334558747682727\nEpoch: 4\tLoss: 0.3067551768361922\nEpoch: 5\tLoss: 0.28700098947922653\nEpoch: 6\tLoss: 0.27102361756080356\nEpoch: 7\tLoss: 0.26235466536527563\nEpoch: 8\tLoss: 0.24686550048170525\nEpoch: 9\tLoss: 0.23969428279223587\nEpoch: 10\tLoss: 0.23953512394479579\nEpoch: 11\tLoss: 0.25531998821857266\nEpoch: 12\tLoss: 0.23111879581574404\nEpoch: 13\tLoss: 0.24429731356182927\nEpoch: 14\tLoss: 0.20557614875090177\nEpoch: 15\tLoss: 0.20529848528675448\nEpoch: 16\tLoss: 0.19752566898557622\nEpoch: 17\tLoss: 0.2114522051210111\nEpoch: 18\tLoss: 0.19891939574338569\nEpoch: 19\tLoss: 0.19559996871173524\nEpoch: 20\tLoss: 0.18053201238400177\nEpoch: 21\tLoss: 0.17926644704422368\nEpoch: 22\tLoss: 0.19594103310912356\nEpoch: 23\tLoss: 0.18048592436998132\nEpoch: 24\tLoss: 0.1775042984555577\nEpoch: 25\tLoss: 0.16877181859708043\nEpoch: 26\tLoss: 0.16599810167021786\nEpoch: 27\tLoss: 0.16452749951485965\nEpoch: 28\tLoss: 0.16729756359957937\nEpoch: 29\tLoss: 0.16709871742833268\nEpoch: 30\tLoss: 0.15797127370921737\nEpoch: 31\tLoss: 0.15653167721520198\nEpoch: 32\tLoss: 0.1654796852165057\nEpoch: 33\tLoss: 0.15546049282034857\nEpoch: 34\tLoss: 0.1540668517918728\nEpoch: 35\tLoss: 0.15221211895179984\nEpoch: 36\tLoss: 0.16557352257702315\nEpoch: 37\tLoss: 0.15124060166400968\nEpoch: 38\tLoss: 0.15459177999472312\nEpoch: 39\tLoss: 0.14560933589492936\nEpoch: 40\tLoss: 0.15199298303162795\nEpoch: 41\tLoss: 0.1434517936916059\nEpoch: 42\tLoss: 0.14415056973252827\nEpoch: 43\tLoss: 0.1436832327751495\nEpoch: 44\tLoss: 0.14082762737942328\nEpoch: 45\tLoss: 0.14220634065448545\nEpoch: 46\tLoss: 0.1427177555513133\nEpoch: 47\tLoss: 0.13783649644292\nEpoch: 48\tLoss: 0.14121461667315782\nEpoch: 49\tLoss: 0.13710656107529798\nEpoch: 50\tLoss: 0.14201740839554997\nEpoch: 51\tLoss: 0.13825116189292252\nEpoch: 52\tLoss: 0.13392872319097757\nEpoch: 53\tLoss: 0.13520608522730443\nEpoch: 54\tLoss: 0.13311949976785234\nEpoch: 55\tLoss: 0.13171014388875382\nEpoch: 56\tLoss: 0.14829897831950142\nEpoch: 57\tLoss: 0.13143106853176342\nEpoch: 58\tLoss: 0.12974194677087542\nEpoch: 59\tLoss: 0.12911103331560916\nEpoch: 60\tLoss: 0.13043500731143512\nEpoch: 61\tLoss: 0.1279133440651005\nEpoch: 62\tLoss: 0.1274443225056998\nEpoch: 63\tLoss: 0.1428017804477343\nEpoch: 64\tLoss: 0.1262995671583113\nEpoch: 65\tLoss: 0.1390421014670323\nEpoch: 66\tLoss: 0.1255127292316151\nEpoch: 67\tLoss: 0.12755172286865832\nEpoch: 68\tLoss: 0.13360079294632318\nEpoch: 69\tLoss: 0.12370625091276198\nEpoch: 70\tLoss: 0.12479368118887574\nEpoch: 71\tLoss: 0.123318274877647\nEpoch: 72\tLoss: 0.12388311763007058\nEpoch: 73\tLoss: 0.1254218636970531\nEpoch: 74\tLoss: 0.12223918336939167\nEpoch: 75\tLoss: 0.12559296492527783\nEpoch: 76\tLoss: 0.1225792634330654\nEpoch: 77\tLoss: 0.1386776088564336\nEpoch: 78\tLoss: 0.12122717748828753\nEpoch: 79\tLoss: 0.12649949254147919\nEpoch: 80\tLoss: 0.11897199122376126\nEpoch: 81\tLoss: 0.11916218580489214\nEpoch: 82\tLoss: 0.11902217872864156\nEpoch: 83\tLoss: 0.12702163637744782\nEpoch: 84\tLoss: 0.11732941501262774\nEpoch: 85\tLoss: 0.11714410916056849\nEpoch: 86\tLoss: 0.11684154901797386\nEpoch: 87\tLoss: 0.13259442647418232\nEpoch: 88\tLoss: 0.11714122115312847\nEpoch: 89\tLoss: 0.11662280865898468\nEpoch: 90\tLoss: 0.11605052781560449\nEpoch: 91\tLoss: 0.11919623232688757\nEpoch: 92\tLoss: 0.11459750536071336\nEpoch: 93\tLoss: 0.11466671120371165\nEpoch: 94\tLoss: 0.11396827672833228\nEpoch: 95\tLoss: 0.11403704943767866\nEpoch: 96\tLoss: 0.1159466388156212\nEpoch: 97\tLoss: 0.11291331383851777\nEpoch: 98\tLoss: 0.12342566831784255\nEpoch: 99\tLoss: 0.11497864794676411\nEpoch: 100\tLoss: 0.11204022527966646\nAccuracy: 0.9649122807017544\n"
    }
   ],
   "source": [
    "logistic_regression_model = LogisticRegression(X_train, y_train)\n",
    "W, loss_hist = logistic_regression_model.fit(lr=1.5, nepoches=100, hist=True)\n",
    "logistic_precision = logistic_regression_model.test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.9473684210526315\n"
    }
   ],
   "source": [
    "svm_model = SVM(X_train, y_train)\n",
    "W, b = svm_model.fit()\n",
    "svm_precision = svm_model.test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}